---
id: rag-session
title: Retrieval-Augmented Generation (RAG)
description: Learn how to build a basic RAG system using chunked documents and vector search.
tags: [RAG, vector databases, retrieval, citation, chunking, colab]
status: live
---

## 🧠 What is RAG?

Retrieval-Augmented Generation (RAG) is a hybrid approach that combines the reasoning and text generation abilities of a language model with access to an external knowledge base. This allows your model to **retrieve fresh, factual information** at inference time and use it to **generate grounded, up-to-date responses**.

**Why it matters for researchers:**  
Models alone cannot “know” recent findings, organizational policy documents, or grey literature. RAG systems let you feed in custom corpora (PDFs, reports, interviews) and generate outputs with inline citations — ideal for research, synthesis, and automated briefings.

## 🔍 RAG Architecture Overview

![Insert architecture diagram from Figma or slides]

1. User sends a query
2. System encodes the query → vector embedding
3. Query is matched against a **vector database** (e.g. Chroma, FAISS)
4. Top-K relevant chunks are retrieved
5. Retrieved texts are inserted into the prompt
6. Model generates an answer using **retrieved facts**, not hallucinated ones

## 🧱 Key Concepts

- **Chunking strategy:** Break your input documents into semantic paragraphs or windows (e.g. 500–800 tokens) to ensure effective embedding and retrieval
- **Vector database:** Stores chunks as embeddings (numerical vectors). Common tools: Chroma, FAISS, Pinecone
- **Retriever model:** Converts both the user query and document chunks into vectors for comparison
- **Citation-aware generation:** Many RAG systems are designed to return sources (e.g. chunk IDs or inline citations)

## 🛠 Code Module: `embed_chroma.md`

➡️ [Embed a custom document collection using ChromaDB](../codebook/embeddings/embed_chroma.md)  
Use this notebook to load documents, chunk them, embed into Chroma, and run a retrieval query.  
_Status: live_

## 🧪 Hands-On Demo (Colab)

```python
# Load documents
# Chunk with overlapping windows
# Embed with SentenceTransformers
# Store in Chroma
# Query and retrieve top results
# Generate with context
