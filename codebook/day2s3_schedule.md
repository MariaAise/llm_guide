---
id: "day2_session3_classification_labeling"
title: "Day 2 – Session 3: Classification & Labeling with Embeddings"
description: "Learn to classify semantic content using embeddings, zero-shot similarity, and fine-tuned classifiers"
---

![fig_day2_session3_header](../shared_assets/visuals/images/fig_day2_session3_header.png)


# Day 2 – Session 3: Getting Better results with Finetuning 

> _"Embeddings don’t just tell us what things **mean** — they let us decide what they **belong to**."_  

---

## 🎯 Session Objectives

✅ Understand upgrade paths to higher accuracy or explainability  

✅ Use fine-tuning with `Trainer` 

✅ Implement LoRA in a real-case scenario

---

## 📘 GitBook Pages

| Page | Purpose | Usage |
|------|---------|--------|
| [`finetuning_lora.md`](../docs/day2/lora_finetuning_guide.md)| 🧭 Understanding fine-tuning and applying LoRA | Core teaching doc |
[peft_lora_setup.md](../docs/day2/peft_lora_setup.md)  |🔬 PEFT - LoRA setup | Jupyter Notebook



## 💻 Notebooks

| Notebook | Purpose | Link |
|----------|---------|------|
| `peft_finetune_demo.ipynb` | Main in-session demo demonstrates lightweight model fine-tuning via LoRA | [Run in Colab](https://colab.research.google.com/github/MariaAise/test/blob/main/peft_finetune_demo.ipynb)


| `classify_policy_stance.ipynb` | classify statements using semantic embedding | [Run in Colab](https://colab.research.google.com/github/MariaAise/test/blob/main/classify_policy_stance.ipynb) |
---
## API Setup

[Gemini API Setup Guide](Gemini_API_Setup_Guide.md)
[Gemini API Setup Guide - screenshots](using_gemini_api_colab.md)

[Hugging Face API Setup Guide](huggingface_api_setup_colab.md)


[OpenAPI Setup Guide](openai_api_setup_colab.md)

---
## 🔮 What’s Next?

➡️ [Day 3 Session 1: Retrieval-Augmented Generation (RAG) →](dday3s1_schedule.md)